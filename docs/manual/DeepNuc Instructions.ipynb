{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *DeepNuc* Manual "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepNuc v0.8. Manual v1.0. Date: 6/15/17. Author: Lawrence Du"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API documentation for *DeepNuc* can be found under DeepNuc/docs/_build/py-modindex.html\n",
    "\n",
    "Currently, (as of version 0.8) not all methods are documented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If *DeepNuc* was not installed as a pip package, the correct path needs to be set at the top of your script in order to use *DeepNuc*.\n",
    "\n",
    "This can be done with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('DEEPNUC_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where DEEPNUC_PATH specifies the path to the DeepNuc directory.\n",
    "\n",
    "All examples in this manual assume usage of this directory structure.\n",
    "\n",
    "Although this manual was written using Jupyter notebook, I would not recommend running training within a notebook environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Training and testing a model from a fasta file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first example, we will train and test a binary classifier using the commonly used fasta format. All entries of an input fasta file need to be the same length.\n",
    "\n",
    "First import the appropriate classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import os.path\n",
    "sys.path.append('../../')\n",
    "import numpy as np\n",
    "\n",
    "from deepnuc.nucdata import *\n",
    "from deepnuc.nucbinaryclassifier import NucBinaryClassifier\n",
    "from deepnuc.databatcher import DataBatcher \n",
    "from deepnuc.modelparams import *\n",
    "from deepnuc.logger import Logger\n",
    "import deepnuc.nucconvmodel as nucconvmodel\n",
    "from deepnuc.crossvalidator import CrossValidator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then specify model parameters.\n",
    "* seq_len: Sequence length. \n",
    "* num_epochs: Number of epochs. An epoch is a single pass through every item in a training set.\n",
    "* learning_rate: Learning rate for gradient descent\n",
    "* batch_size: Mini-batch size.\n",
    "* keep_prob: The keep probability for Dropout. A keep prob of .6 will randomly drop 40% of weights on each training cycle.\n",
    "* beta1: A parameter used by the AdamOptimizer\n",
    "* concat_revcom_input: If set to true, the reverse complemented sequence nucleotide sequence for a item will be concatenated to the input vector.\n",
    "* inference_method_key: A string value key for different methods found in nucconvmodel.py. Currently can be set to \"inferenceA\" or \"inferenceD\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = ModelParams(\n",
    "                         seq_len=600,\n",
    "                         num_epochs=35,\n",
    "                         learning_rate=1e-4,\n",
    "                         batch_size=24,\n",
    "                         keep_prob=0.5,\n",
    "                         beta1=0.9,\n",
    "                         concat_revcom_input=False,\n",
    "                         inference_method_key=\"inferenceA\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a NucData type object from your fasta file. NucData type objects are described in the nucdata.py module. There are many different types of NucData objects for different filetypes. We will use NucDataBedMem which reads all nucleotide sequences into the computer's memory.\n",
    "\n",
    "Note that since most bed files will have irregularly sized entries (end-start will differ for most lines), this the NucDataBedMem constructor has an option to only pull objects within a window around the start coordinate to make things nice and even. \n",
    "\n",
    "This constructor also has an option to automatically generate a dinucleotide shuffled negative class fasta file from each bed file entry. More information can be found in the API docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bed_file = \"kruesi_bed_0_4.bed\"\n",
    "genome_file=\"WS230_genome.fa\"\n",
    "chr_sizes_file=\"WS230_genome.chr.sizes\"\n",
    "seq_len=600\n",
    "skip_first=False\n",
    "\n",
    "nuc_data = NucDataBedMem( bed_file,\n",
    "                          genome_file,\n",
    "                          chr_sizes_file,\n",
    "                          seq_len=600,\n",
    "                          skip_first= False, #skip header line if true\n",
    "                          gen_dinuc_shuffle=True,\n",
    "                          neg_data_reader=None,\n",
    "                          start_window=[-300,300]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NucData objects encapsulate data from different file formats, but aren't used for training and testing directly. DataBatcher objects are useful for slicing NucData objects into training and testing sets by index. DataBatcher objects also shuffle records by index every epoch and pull randomized mini-batches for training without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#First scramble the indices you want to use\n",
    "seed = 12415\n",
    "perm_indices = np.random.RandomState(seed).\\\n",
    "                    permutation(range(nuc_data.num_records))\n",
    "    \n",
    "#Slice out 20% of indices for testing and 80% for training    \n",
    "test_frac = .2\n",
    "test_size = int(nuc_data.num_records*test_frac)\n",
    "train_size = nuc_data.num_records - test_size\n",
    "test_indices = perm_indices[0:int(nuc_data.num_records*test_frac)]\n",
    "train_indices = np.setdiff1d(perm_indices,test_indices)\n",
    "\n",
    "#Create training and testing batchers\n",
    "train_batcher = DataBatcher(nuc_data,train_indices)\n",
    "test_batcher = DataBatcher(nuc_data,test_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the training and testing batchers, we can now run training from within a Tensorflow session.\n",
    "\n",
    "Note: Training parameters can be passed directly to NucBinaryClassifier, but in many situtations, using the ModelParams object can be useful for writing methods which train off different dataset using the same training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "save_dir=\"test_train1\"\n",
    "os.makedirs(save_dir)\n",
    "with tf.Session() as sess:\n",
    "    nc_test = NucBinaryClassifier(sess,\n",
    "                                train_batcher,\n",
    "                                test_batcher,\n",
    "                                params.num_epochs,\n",
    "                                params.learning_rate,\n",
    "                                params.batch_size,\n",
    "                                params.seq_len,\n",
    "                                save_dir,\n",
    "                                params.keep_prob,\n",
    "                                params.beta1\n",
    "                                params.concat_revcom_input,\n",
    "                                params.inference_method_key)\n",
    "\n",
    "    nc_test.build_model()\n",
    "    nc_test.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nc_test.build_model() will also load trained models. For example. After running training, the following line can be used to evaluate metrics from a differerent test or evaluation batcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nc_test.build_model()\n",
    "nc_test.eval_model_metrics(different_batcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a dinucleotide shuffled file manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making dinucleotide shuffled files can also be done manually using the BedReader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Training and testing a model from a fasta file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing a from a fasta file is identical to training and testing from a bed file. The only difference is changing the nuc_data object from a NucDataBedMem to a NucDataFastaMem.\n",
    "\n",
    "NucDataFastaMem takes a list of fasta files as an argument. For binary classification this list should be length = 2. The first fasta file passed in the list is the negative class and the second file passed should be the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fasta_neg = \"kruesi_tss_-300_300_dinuc_shuffle.fa\"\n",
    "fasta_pos = \"kruesi_tss_-300_300.fa\"\n",
    "nuc_data = NucDataFastaMem([fasta_neg,fasta_pos],seq_len=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Performing k-folds cross-validation using a bed file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a model trained and evaluating a test set is nice, but in a real world situation, we want to have a way to know how well our model performed. This is where k-folds cross-validation is useful. Cross validation can be done in the following manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cv_save_dir = \"cv_test1\"\n",
    "cv_test = CrossValidator(params,\n",
    "                        nuc_data,\n",
    "                        cv_save_dir,\n",
    "                        seed=124155,\n",
    "                        k_folds=3,\n",
    "                        test_frac=0.15)\n",
    "cv.run()\n",
    "\n",
    "#Calculate average of k-fold metrics and display in terminal\n",
    "cv.calc_avg_k_metrics()\n",
    "\n",
    "#Plot curves\n",
    "cv.plot_auroc_auprc(\"cv test curves\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that cv.run() does not need to be called from within a tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Performing a grid search with cross-validation using a bed file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of k-folds cross-validation, we want to have cross-validation metrics for different hyperparameter combinations. This is where a grid search is useful. Performing a grid search is one of the simplest and most common ways of using *DeepNuc*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A grid search requires initialization of a GridParams object. This object is similar to ModelParams except all arguments except seq_len should be passed as lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gsave_dir=\"gridtest1\"\n",
    "gparams = GridParams(\n",
    "                      seq_len= seq_len,\n",
    "                      num_epochs=[55],\n",
    "                      learning_rate=[1e-4],\n",
    "                      batch_size=[24],\n",
    "                      keep_prob=[0.5],\n",
    "                      beta1=[0.9],\n",
    "                      concat_revcom_input = [True,False],\n",
    "                      inference_method_key=[\"inferenceA\",\"inferenceD\"])\n",
    "                    )\n",
    "    \n",
    "nuc_data = NucDataBed(bed_file,\n",
    "                      genome_file,\n",
    "                      chr_sizes_file,\n",
    "                      seq_len=600,\n",
    "                      skip_first= False, #skip header line if true\n",
    "                      gen_dinuc_shuffle=True,\n",
    "                      start_window=[-300,300]\n",
    "                      )\n",
    "\n",
    "gsearch = GridSearch(\n",
    "                        gparams,\n",
    "                        nuc_data,\n",
    "                        save_dir=gsave_dir,\n",
    "                        seed = 29517,\n",
    "                        k_folds=3,\n",
    "                        test_frac=.2,\n",
    "                        fig_title_prefix = \"\")\n",
    "gsearch.run() #Does not need to be run within tf.Session()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a grid search is performed, the model can be loaded and final training performed on the best classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    best_classifier,best_model_params = gsearch.best_binary_classifier(sess,\"auroc\")\n",
    "    print \"\\n\\n\\nBest model params for {}\".format(tss_bed)\n",
    "    best_model_params.print_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best_classifier can be treated as any other NucBinaryClassifier object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    best_classifier.eval_model_metrics(different_batcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if running back to back grid search or training runs from the same script, you should reset the default graph with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Using a fasta or bed file as a negative class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To specify a specific bed or fasta file to use as a negative class, pass a BedReader or FastaReader to the neg_data_reader parameter of NucDataBedMem when making a NucData object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len=600\n",
    "specific_neg_file=\"my_specific_file.fa\"\n",
    "my_neg_reader = FastaReader(specific_neg_file,seq_len)\n",
    "\n",
    "\n",
    "bed_file = \"kruesi_bed_0_4.bed\"\n",
    "genome_file=\"WS230_genome.fa\"\n",
    "chr_sizes_file=\"WS230_genome.chr.sizes\"\n",
    "\n",
    "skip_first=False\n",
    "\n",
    "nuc_data = NucDataBedMem( bed_file,\n",
    "                          genome_file,\n",
    "                          chr_sizes_file,\n",
    "                          seq_len=600,\n",
    "                          skip_first= False, #skip header line if true\n",
    "                          gen_dinuc_shuffle=False\n",
    "                          neg_data_reader= my_neg_reader\n",
    "                          start_window=[-300,300]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since training should be performed with balanced data, you may want to set a limit on the number of negative items you pull from a specified file. This is available as an argument to the FastaReader object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len=600\n",
    "specific_neg_file=\"my_specific_file.fa\"\n",
    "\n",
    "my_neg_reader = FastaReader(specific_neg_file, seq_len, pull_limit=4121)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Using DeepNuc for regression (untested)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression has yet to be fully implemented. Running models for regression problems (ie: protein binding microarray data) is available through the nucregressor.NucRegressor class. There is also a cross-validation class implemented as crossvalidator.RegressorCrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addenum 1: Adding new models using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*See nucconvmodels.py for examples*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
